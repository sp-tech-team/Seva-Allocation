{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup RAG Index Input Corpus for Past Participant Data (DEPRECATED)\n",
    "Note that this approach is now deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(\"data/past_participants_split/\"), exist_ok=True)\n",
    "df = pd.read_csv('data/past_participant_info.csv')\n",
    "df = df.dropna(subset=['VRF ID', 'Skillset', 'Person Id']).reset_index(drop=True)\n",
    "train_ratio = 0.8\n",
    "train_df, eval_df = train_test_split(df['Person Id'], test_size=(1 - train_ratio), random_state=42)\n",
    "train_df.to_csv(\"data/past_participants_split/train_ids.csv\", index=False)\n",
    "eval_df.to_csv(\"data/past_participants_split/eval_ids.csv\", index=False)\n",
    "\n",
    "def create_applicant_info_corpus(applicant_info_csv: str, train_ids_csv: str, max_samples: int = -1) -> str:\n",
    "    \"\"\"Create a corpus of applicant information from a CSV file.\n",
    "\n",
    "    Args:\n",
    "        applicant_info_csv: Path to the CSV file containing applicant information.\n",
    "        train_ids_csv: Path to the CSV file containing the train IDs.\n",
    "        max_samples: Maximum number of samples to use. If -1, use all samples.\n",
    "\n",
    "    Returns:\n",
    "        A corpus of applicant information.\n",
    "    \"\"\"\n",
    "    train_ids_df = pd.read_csv(train_ids_csv)\n",
    "    max_samples = len(train_ids_df) if max_samples == -1 else min(max_samples, len(train_ids_df))\n",
    "    train_ids_df = train_ids_df.sample(n=max_samples, random_state=42)\n",
    "    job_assigns_df = pd.read_csv(applicant_info_csv)\n",
    "    job_assigns_df = train_ids_df.merge(job_assigns_df, on='Person Id', how='inner')\n",
    "    job_assigns_df['job'] = job_assigns_df['VRF ID'].apply(lambda x: x.split('-')[1])\n",
    "    job_assigns_df['Skillset'] = job_assigns_df['Skillset'].apply(lambda x: x.replace('\\n', ' '))\n",
    "    job_assigns_df['summary'] = \" Participant with skills: \" + job_assigns_df['Skillset'] + \" was assigned to job: \" + job_assigns_df['job'] + \".\\n\"\n",
    "    corpus = ''.join(job_assigns_df['summary'])\n",
    "    return corpus\n",
    "\n",
    "corpus = create_applicant_info_corpus('data/past_participant_info.csv', 'data/generated_participants_training/train_ids.csv', -1)\n",
    "with open(\"data/past_participants_split/train_corpus.txt\", \"w\") as file:\n",
    "    file.write(corpus)\n",
    "eval_ids_df = pd.read_csv('data/past_participants_split/eval_ids.csv')\n",
    "eval_data = eval_ids_df.merge(df, on='Person Id', how='inner')\n",
    "eval_data[\"eval_input\"] =  \" Participant \" + eval_data[\"Person Id\"].astype(str) + \" has skills: \" + eval_data['Skillset']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
