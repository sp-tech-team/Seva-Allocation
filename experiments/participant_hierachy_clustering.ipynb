{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seva_data_path = \"../toy_data/TOY_seva_modified20apr.xlsx\"\n",
    "candidate_info_df = pd.read_excel(seva_data_path)\n",
    "\n",
    "skills_jobs_df = pd.DataFrame()\n",
    "skills_jobs_df[\"SP ID\"] = candidate_info_df[\"SP ID\"]\n",
    "skills_jobs_df['Skills Jobs'] = candidate_info_df['Skills'].fillna(' ')\n",
    "# skills_jobs_df['Skills Jobs'] = candidate_info_df['Work Experience/Designation'].fillna(' ') + \" \" + candidate_info_df['Any Additional Skills'].fillna(' ') + \" \" + \\\n",
    "#         candidate_info_df['Computer Skills'].fillna(' ') + \" \" + candidate_info_df['Skills'].fillna(' ') + \" \" + candidate_info_df['Skills.1'].fillna(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMBEDDING SKILLS...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3db5a6edbea421daab298fde5d23c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Skills and Jobs Embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-roberta-large-v1', device='cpu')\n",
    "print('EMBEDDING SKILLS...')\n",
    "embeddings = model.encode(skills_jobs_df['Skills Jobs'], convert_to_tensor=True, show_progress_bar=True, device='cpu')\n",
    "embeddings_np = embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Hierarchical Clustering\n",
    "Z = sch.linkage(\n",
    "    embeddings_np,\n",
    "    method='complete',\n",
    "    metric='cosine',\n",
    "    optimal_ordering=True) # set to false when large scale (slows down computation)\n",
    "\n",
    "# Step 4: Plot the dendrogram to visualize the hierarchy tree\n",
    "plt.figure(figsize=(20,10))\n",
    "sch.dendrogram(Z,labels=skills_jobs_df['SP ID'].values,  leaf_rotation=0, count_sort=True, distance_sort=True, orientation='right', leaf_font_size=6)\n",
    "\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Index of Embeddings\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('participant-dendrogram.png', format='png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_hierarchy_tree(Z, skills_jobs_df, dist=0.5):\n",
    "    cluster_labels = sch.fcluster(Z, t=dist, criterion='distance')\n",
    "    clustered = defaultdict(list)\n",
    "    for i, label in enumerate(cluster_labels):\n",
    "        clustered[label].append(skills_jobs_df['Skills Jobs'].iloc[i])  # Group string names by cluster label\n",
    "    return clustered\n",
    "\n",
    "def print_cluster(clustered):\n",
    "    for i in range(0, len(clustered)):\n",
    "        print(f\"Cluster {i}: {clustered[i]}\")\n",
    "\n",
    "\n",
    "dist_threshs = np.arange(.1, 1, .1)\n",
    "histograms = dict()\n",
    "clusters_for_threshs = []\n",
    "for dist in dist_threshs:\n",
    "    print(f\"Clusters at distance threshold {dist}\")\n",
    "    clustered = cluster_hierarchy_tree(Z, skills_jobs_df, dist)\n",
    "    clusters_for_threshs.append(clustered)\n",
    "    print_cluster(clustered)\n",
    "    histograms[dist] = [len(strings) for strings in clustered.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (dist, histogram) in enumerate(histograms.items()):\n",
    "    # Step 1: Get the size of each cluster\n",
    "    # cluster_sizes = [len(strings) for strings in clusters.values()]\n",
    "    \n",
    "    # Step 2: Create the histogram\n",
    "    plt.figure(i)  # Create a new figure for each plot\n",
    "    plt.hist(histogram, bins=range(1, max(histogram)+2), edgecolor='black')\n",
    "    plt.xlabel('Cluster Size')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(f'Histogram of Cluster Sizes for Dist Thresh: {dist}')\n",
    "\n",
    "# Show all plots at once (after the loop)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file created successfully!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Step 1: Collect all the cluster data into rows\n",
    "csv_data = []\n",
    "\n",
    "# Loop through the list of dictionaries\n",
    "for clusters in clusters_for_threshs:\n",
    "    # For each dictionary, get the cluster ID and associated array (cluster of strings)\n",
    "    #for cluster_id, cluster in clusters.items():\n",
    "    for i in range(0, len(clusters)):\n",
    "        # Create a row where the first entry is the cluster ID, followed by the cluster items\n",
    "        row = [f\"Cluster: {i}\"] + clusters[i]\n",
    "        csv_data.append(row)\n",
    "\n",
    "# Step 2: Find the maximum row length to ensure all rows have the same number of columns\n",
    "max_length = max(len(row) for row in csv_data)\n",
    "\n",
    "# Step 3: Pad each row with empty strings (or None) to match the max length\n",
    "for row in csv_data:\n",
    "    row.extend([''] * (max_length - len(row)))\n",
    "\n",
    "# Step 4: Write the jagged data to a CSV file\n",
    "with open('clusters.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print(\"CSV file created successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
