{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade --quiet  langchain langchain-community langchain-ollama langchain-experimental neo4j tiktoken yfiles_jupyter_graphs python-dotenv json-repair langchain-openai langchain_core\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "from collections import defaultdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vrf_data_path = \"../../full_data/vrf_data.xlsx\"\n",
    "seva_data_path = \"../../full_data/seva_modified2.xlsx\"\n",
    "\n",
    "vrf_df = pd.read_excel(vrf_data_path)\n",
    "candidate_info_df = pd.read_excel(seva_data_path)\n",
    "vrf_jobs_df = vrf_df['/'].dropna().drop_duplicates().reset_index(drop=True)#[:10]\n",
    "corpus_str = \",\\n\".join(vrf_jobs_df)\n",
    "\n",
    "# docs = [Document(page_content=corpus_str)]\n",
    "\n",
    "# # Step 3: Initialize the RecursiveCharacterTextSplitter\n",
    "# text_splitter = RecursiveCharacterTextSplitter(chunk_size=40, chunk_overlap=10)\n",
    "\n",
    "# # Step 4: Split the document\n",
    "# documents = text_splitter.split_documents(documents=docs)\n",
    "documents = [\n",
    "    Document(page_content=corpus_str)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm_type = 'chat_gpt'\n",
    "if llm_type == 'chat_gpt':\n",
    "    model = \"gpt-4o\" # 'gpt-4o-mini'\n",
    "    llm = ChatOpenAI(model=model, api_key=openai_api_key)\n",
    "elif llm_type == 'llama':\n",
    "    llm = OllamaFunctions(model=\"llama3.1\", temperature=0, format=\"json\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm)\n",
    "    # allowed_nodes=[\"Job\"],\n",
    "    # allowed_relationships=[\"PARENT_TO\", \"RELATED_TO\", \"SIMILAR_TO\"],)\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph()\n",
    "\n",
    "# graph.add_graph_documents(\n",
    "#     graph_documents,\n",
    "#     baseEntityLabel=True,\n",
    "#     include_source=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2007637764d045e5b65cda47455f047f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show_graph():\n",
    "    uri = os.environ.get(\"NEO4J_URI\")\n",
    "    auth = (os.environ.get(\"NEO4J_USERNAME\"), os.environ.get(\"NEO4J_PASSWORD\"))\n",
    "    driver = GraphDatabase.driver(uri, auth=auth)\n",
    "    session = driver.session()\n",
    "    widget = GraphWidget(graph=session.run(\"MATCH (s) - [r:!MENTIONS] -> (t) RETURN s, r, t\").graph())\n",
    "    widget.node_label_mapping = 'id'\n",
    "    return widget\n",
    "\n",
    "show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
